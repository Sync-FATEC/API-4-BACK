# ğŸ“˜ DocumentaÃ§Ã£o de Testes de IntegraÃ§Ã£o

## ğŸ” O que sÃ£o Testes de IntegraÃ§Ã£o?

Os testes de integraÃ§Ã£o validam a interaÃ§Ã£o entre mÃºltiplos componentes ou camadas do sistema. Diferente dos testes unitÃ¡rios, que testam funÃ§Ãµes isoladas, os testes de integraÃ§Ã£o verificam como diferentes partes do sistema trabalham juntas. No nosso contexto, validamos principalmente:

- A interaÃ§Ã£o entre *use cases* e repositÃ³rios
- O fluxo completo de dados entre a aplicaÃ§Ã£o e o banco de dados
- A execuÃ§Ã£o das regras de negÃ³cio de ponta a ponta

---

## ğŸ“¦ Estrutura dos Testes

Todos os testes de integraÃ§Ã£o seguem a seguinte estrutura:

```
tests/
 â””â”€â”€ integration/
     â”œâ”€â”€ config/
     |    â””â”€â”€ seeds/         # FunÃ§Ãµes para gerar dados de teste
     |    â””â”€â”€ setup/         # ConfiguraÃ§Ã£o do ambiente de teste
     â”œâ”€â”€ <nome-da-entidade>/ # Pasta para entidade (ex: measures, station)
          â””â”€â”€ <nome-do-usecase>.test.ts
```

### Detalhamento dos DiretÃ³rios:

- `config/seeds/`: ContÃ©m funÃ§Ãµes que preparam os dados necessÃ¡rios para os testes. Cada seed deve utilizar os *use cases* reais do sistema para criar os dados.
- `config/setup/`: Possui arquivos para inicializaÃ§Ã£o do banco de dados de teste, limpeza entre os testes e configuraÃ§Ã£o do ambiente.
- `<nome-da-entidade>/`: DiretÃ³rios organizados por domÃ­nio (ex: measures, station, parameters).
- `*.test.ts`: Arquivos com os testes de integraÃ§Ã£o, nomeados conforme o use case testado.

---

## ğŸ§ª Passo a Passo para Criar um Novo Teste de IntegraÃ§Ã£o

### 1. Identificar o Use Case a ser Testado

Primeiro, identifique claramente qual *use case* vocÃª precisa testar. Verifique no Jira os critÃ©rios de aceitaÃ§Ã£o e regras de negÃ³cio relacionadas.

### 2. Criar o Arquivo de Teste na Pasta Correta

O nome do arquivo de teste deve seguir o padrÃ£o:  
`<NomeDoUseCase>.test.ts`  

Exemplo: Para testar a criaÃ§Ã£o de mediÃ§Ãµes, crie o arquivo:
`tests/integration/measures/CreateMeasureUseCase.test.ts`

### 3. Estrutura Base do Arquivo de Teste

```ts
import { DataSource } from "typeorm";
import SetupIntegration, { getDataSource } from "../config/setup/SetupIntegration";
import { clearDatabase } from "../config/setup/DatabaseCleaner";

// Importar os repositÃ³rios e use cases necessÃ¡rios
import { NomeDoUseCase } from "../../../src/application/use-cases/pasta/NomeDoUseCase";
import { NomeDoRepositorio } from "../../../src/infrastructure/repositories/NomeDoRepositorio";

// Declarar variÃ¡veis que serÃ£o utilizadas nos testes
let dataSource: DataSource;
let useCase: NomeDoUseCase;
let repositorio: NomeDoRepositorio;

// Configurar o ambiente antes de todos os testes
beforeAll(async () => {
  await SetupIntegration();
  dataSource = getDataSource();
});

// Limpar o banco e configurar as instÃ¢ncias antes de cada teste
beforeEach(async () => {
  await clearDatabase(dataSource);
  repositorio = new NomeDoRepositorio();
  useCase = new NomeDoUseCase(repositorio);
  // Inicialize outros repositÃ³rios ou dependÃªncias necessÃ¡rias
});

// Limpar recursos apÃ³s todos os testes
afterAll(async () => {
  await dataSource.destroy();
});

// Exemplo de teste bem-sucedido
test('âœ… Deve executar com sucesso o caso de uso', async () => {
  // Preparar os dados utilizando seeds
  // Executar o caso de uso
  // Verificar os resultados com expects
});

// Exemplo de teste de erro
test('âŒ Deve retornar erro quando [condiÃ§Ã£o de erro]', async () => {
  // Preparar o cenÃ¡rio de erro
  // Verificar se o erro Ã© lanÃ§ado corretamente
  await expect(
    // Chamada do use case com parÃ¢metros que devem gerar erro
  ).rejects.toThrow("Mensagem de erro esperada");
});
```

---

## ğŸŒ± Como Criar e Utilizar Seeds

As seeds sÃ£o fundamentais para preparar o ambiente de teste com dados consistentes. Sempre crie os dados utilizando os *use cases* reais, nunca inserindo diretamente no banco.

### Estrutura de uma Seed:

```ts
// config/seeds/createNomeEntidadeSeed.ts
import { UseCase } from "../../../src/application/use-cases/pasta/UseCase";
import { Repositorio } from "../../../src/infrastructure/repositories/Repositorio";
import { DTO } from "../../../src/web/dtos/pasta/DTO";

export async function createNomeEntidadeSeed(parametro1: string, parametro2: number) {
  // Instanciar o use case e repositÃ³rios necessÃ¡rios
  const useCase = new UseCase(new Repositorio());
  
  // Criar o DTO com os dados de teste
  const dto = new DTO(parametro1, parametro2);
  
  // Executar o use case e retornar a entidade criada
  return await useCase.execute(dto);
}
```

### Exemplo Real de Seed para EstaÃ§Ã£o:

```ts
// createStationSeed.ts
import { CreateStationUseCase } from "../../../src/application/use-cases/station/CreateStationUseCase";
import StationRepository from "../../../src/infrastructure/repositories/StationRepository";
import CreateStationDTO from "../../../src/web/dtos/station/CreateStationDTO";

export async function createStationSeed() {
  const useCase = new CreateStationUseCase(new StationRepository());
  const dto = new CreateStationDTO("EstaÃ§Ã£o Centro", "uuid-centro", "-23.5505", "-46.6333");
  return await useCase.execute(dto);
}
```

### Utilizando Seeds nos Testes:

```ts
test('âœ… Deve criar uma mediÃ§Ã£o', async () => {
  // CriaÃ§Ã£o dos dados necessÃ¡rios usando seeds
  const station = await createStationSeed();
  const typeParameter = await createTypeParameterSeed();
  const parameter = await createParameterSeed(typeParameter, station);
  
  // Executar o caso de uso a ser testado
  const measure = await createMeasuresSeed(parameter.id);

  // ValidaÃ§Ã£o dos resultados
  expect(measure).toBeDefined();
  expect(measure.parameter.id).toBe(parameter.id);
  expect(measure.parameter.idTypeParameter).toEqual(typeParameter);
  expect(measure.parameter.idStation).toEqual(station);
});
```

---

## ğŸ§‘â€ğŸ’» Fluxo Completo para o Desenvolvedor

1. **Analise os requisitos:**
   - Consulte o Jira para entender a funcionalidade
   - Identifique os critÃ©rios de aceitaÃ§Ã£o e regras de negÃ³cio
   - Mapeie os *use cases* envolvidos

2. **Planeje os testes:**
   - Identifique cenÃ¡rios de sucesso e falha
   - Liste as dependÃªncias e dados necessÃ¡rios
   - Verifique quais seeds precisarÃ¡ criar ou reutilizar

3. **Implemente as seeds necessÃ¡rias:**
   - Crie arquivos em `config/seeds/` para cada tipo de dado
   - Utilize os *use cases* reais para criar os dados
   - Parametrize as seeds para permitir flexibilidade

4. **Desenvolva os testes de integraÃ§Ã£o:**
   - Crie o arquivo no formato `<NomeDoUseCase>.test.ts`
   - Implemente a configuraÃ§Ã£o bÃ¡sica (beforeAll, beforeEach, afterAll)
   - Implemente testes para cenÃ¡rios de sucesso e falha
   - Utilize assertions especÃ­ficas para validar o comportamento

5. **Execute e valide os testes:**
   - Execute os testes usando `npm run test:integration`
   - Verifique se todos os cenÃ¡rios estÃ£o cobertos
   - Confirme que as regras de negÃ³cio estÃ£o sendo validadas

---

## ğŸ§¾ Exemplo Completo de Teste de IntegraÃ§Ã£o

```ts
// CreateMeasureUseCase.test.ts
import { DataSource } from "typeorm";
import { RegisterMeasureUseCase } from "../../../src/application/use-cases/measure/RegisterMeasureUseCase";
import { MeasureRepository } from "../../../src/infrastructure/repositories/MeasureRepository";
import { ParameterRepository } from "../../../src/infrastructure/repositories/ParameterRepository";
import StationRepository from "../../../src/infrastructure/repositories/StationRepository";
import SetupIntegration, { getDataSource } from "../config/setup/SetupIntegration";
import { clearDatabase } from "../config/setup/DatabaseCleaner";
import { createParameterSeed } from "../config/seeds/createParameterSeed";
import { createStationSeed } from "../config/seeds/createStationSeed";
import { createTypeParameterSeed } from "../config/seeds/createTypeParameterSeed";
import { createMeasuresSeed } from "../config/seeds/createMeasuresSeed";

let dataSource: DataSource;
let useCase: RegisterMeasureUseCase;
let measureRepo: MeasureRepository;
let parameterRepo: ParameterRepository;
let stationRepo: StationRepository;

beforeAll(async () => {
    await SetupIntegration();
    dataSource = getDataSource();
});

beforeEach(async () => {
    await clearDatabase(dataSource);
    measureRepo = new MeasureRepository();
    parameterRepo = new ParameterRepository();
    stationRepo = new StationRepository();
    useCase = new RegisterMeasureUseCase(measureRepo, parameterRepo, stationRepo);
});

afterAll(async () => {
    await dataSource.destroy();
});

// CenÃ¡rio de sucesso
test('âœ… Deve criar uma mediÃ§Ã£o', async () => {
    const station = await createStationSeed();
    const typeParameter = await createTypeParameterSeed();
    const parameter = await createParameterSeed(typeParameter, station);
    const measure = await createMeasuresSeed(parameter.id);
    
    expect(measure).toBeDefined();
    expect(measure.parameter.id).toBe(parameter.id);
    expect(measure.parameter.idTypeParameter).toEqual(typeParameter);
    expect(measure.parameter.idStation).toEqual(station);
    expect(measure.parameter.idTypeParameter.name).toBe(typeParameter.name);
    expect(measure.unixTime).toBe(measure.unixTime);
    expect(measure.value).toBe(measure.value);
});

// CenÃ¡rio de erro
test('âŒ Deve retornar um erro ao criar uma mediÃ§Ã£o com um parÃ¢metro nÃ£o existente', async () => {
    await expect(
        createMeasuresSeed('2bc8680a-8ecf-46db-bc63-90a0925eb66b')
    ).rejects.toThrow("Parametro nÃ£o encontrado");
});
```

---

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente de Testes

### Arquivos de ConfiguraÃ§Ã£o:

- **SetupIntegration.ts**: Inicializa o TypeORM com o banco de dados de teste. 
- **DatabaseCleaner.ts**: Limpa todas as tabelas do banco entre os testes.
- **TeardownIntegration.ts**: Encerra as conexÃµes apÃ³s os testes.

### Executando os Testes:

```bash
# Executa todos os testes de integraÃ§Ã£o
npm run test:integration
```

### ğŸ“š VersÃµes das Bibliotecas

Para garantir a compatibilidade e funcionamento correto dos testes, utilize as seguintes versÃµes das bibliotecas principais:

```json
{
  "dependencies": {
    "typeorm": "^0.3.20",
    "pg": "^8.11.3",
    "testcontainers": "^10.0.0",
    "jest": "^29.7.0",
    "@types/jest": "^29.5.12",
    "ts-jest": "^29.1.2"
  }
}
```

---

## ğŸ¯ PrÃ¡ticas Recomendadas

1. **Dados consistentes**:
   - Sempre use seeds para criar dados de teste
   - Nunca faÃ§a manipulaÃ§Ã£o direta do banco
   - Mantenha os dados realistas

2. **NomeaÃ§Ã£o clara**:
   - Testes com nomes descritivos indicando o cenÃ¡rio
   - Prefixo "âœ…" para testes de sucesso
   - Prefixo "âŒ" para testes de falha

3. **ValidaÃ§Ãµes completas**:
   - Teste todas as propriedades relevantes
   - Valide casos de borda e exceÃ§Ãµes
   - Verifique mensagens de erro especÃ­ficas

4. **Isolamento**:
   - Cada teste deve ser independente
   - O banco deve ser limpo entre cada teste
   - Evite dependÃªncias entre testes

---

## âœ… Checklist de Qualidade

Antes de finalizar sua implementaÃ§Ã£o de testes, verifique:

- [ ] Os testes cobrem todos os cenÃ¡rios definidos nos critÃ©rios de aceitaÃ§Ã£o
- [ ] Os dados sÃ£o preparados via seeds usando use cases reais
- [ ] Existem testes para todos os casos de erro relevantes
- [ ] O banco de dados Ã© limpo corretamente entre os testes
- [ ] As mensagens de erro esperadas estÃ£o sendo validadas
- [ ] A cobertura de cÃ³digo estÃ¡ adequada (>80%)
- [ ] Os testes sÃ£o legÃ­veis e bem documentados

---

**Com testes de integraÃ§Ã£o bem estruturados, garantimos que o sistema funciona corretamente como um todo, reduzindo riscos em produÃ§Ã£o e aumentando a confianÃ§a no cÃ³digo.**

