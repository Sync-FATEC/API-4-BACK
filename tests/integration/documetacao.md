# ğŸ“˜ DocumentaÃ§Ã£o de Testes de IntegraÃ§Ã£o - Equipe Sync

## ğŸ” O que sÃ£o Testes de IntegraÃ§Ã£o?

Os testes de integraÃ§Ã£o validam a interaÃ§Ã£o entre mÃºltiplos componentes ou camadas do sistema. Diferente dos testes unitÃ¡rios, que testam funÃ§Ãµes isoladas, os testes de integraÃ§Ã£o verificam como diferentes partes do sistema trabalham juntas. No nosso contexto, validamos principalmente:

- A interaÃ§Ã£o entre use cases, repositÃ³rios e banco de dados
- O fluxo completo de dados entre a aplicaÃ§Ã£o e o banco de dados
- A execuÃ§Ã£o das regras de negÃ³cio de ponta a ponta

## âš™ï¸ Processo de DefiniÃ§Ã£o dos Testes de IntegraÃ§Ã£o

### ğŸ“Œ Como os Testes SÃ£o Definidos?

Os testes de integraÃ§Ã£o sÃ£o definidos com base nos **critÃ©rios de aceitaÃ§Ã£o** estabelecidos pelo **Product Owner (PO)** durante o **planejamento da sprint**. Esses critÃ©rios descrevem os comportamentos esperados da funcionalidade e servem como referÃªncia direta para a criaÃ§Ã£o dos testes automatizados.

AlÃ©m disso, **o time valida coletivamente, durante a sprint review**, o que realmente precisa ser coberto por testes de integraÃ§Ã£o â€” priorizando fluxos crÃ­ticos e pontos de maior risco.

Durante o desenvolvimento, os desenvolvedores sÃ£o responsÃ¡veis por implementar os testes com foco em:

- Validar o comportamento da aplicaÃ§Ã£o de ponta a ponta (atravessando todas as camadas);
- Garantir a integraÃ§Ã£o correta entre *use cases*, repositÃ³rios e banco de dados;
- Verificar se os dados fluem corretamente entre entrada (DTOs), lÃ³gica de negÃ³cio e persistÃªncia;
- Confirmar que erros e exceÃ§Ãµes previstos sÃ£o tratados e retornados de forma adequada.

### ğŸ‘¥ PapÃ©is e Responsabilidades

- **Product Owner (PO)**
  - Define os critÃ©rios de aceitaÃ§Ã£o com base nas regras de negÃ³cio.
  - Esses critÃ©rios norteiam os testes automatizados.

- **Desenvolvedores**
  - Implementam os testes de integraÃ§Ã£o com base nos critÃ©rios definidos.
  - Garantem que o comportamento do sistema estÃ¡ correto em cenÃ¡rios reais.
  - Utilizam seeds e utilitÃ¡rios padronizados para preparar os dados de teste.

- **DevOps (Teste de integraÃ§Ã£o)**
  - Apoia na padronizaÃ§Ã£o de boas prÃ¡ticas.
  - MantÃ©m exemplos reutilizÃ¡veis (seeds, setup, etc).

## ğŸ§‘â€ğŸ’» Fluxo Completo para o Desenvolvedor

### 1. Analise os Requisitos
- Consulte o Jira para entender a funcionalidade.
- Identifique os critÃ©rios de aceitaÃ§Ã£o e regras de negÃ³cio.
- Mapeie os *use cases* envolvidos na implementaÃ§Ã£o e nos testes.

### 2. Planeje os Testes
- Liste os cenÃ¡rios de sucesso e falha.
- Identifique os dados e dependÃªncias necessÃ¡rios.
- Verifique se jÃ¡ existem seeds reutilizÃ¡veis ou se serÃ¡ necessÃ¡rio criar novas.

### 3. Implemente as Seeds
- Crie arquivos em `tests/integration/config/seeds/`.
- Use *use cases reais* para popular os dados â€” nunca insira direto no banco.
- Parametrize as seeds para facilitar a reutilizaÃ§Ã£o entre testes.

### 4. Desenvolva os Testes de IntegraÃ§Ã£o
- Crie o arquivo no padrÃ£o: `<NomeDoUseCase>.test.ts`.
- Configure o ambiente de teste (uso de `beforeAll`, `beforeEach`, `afterAll`).
- Implemente testes para cobrir os cenÃ¡rios planejados (sucesso e erro).
- Use `expect(...)` para validar resultados e regras de negÃ³cio.

### 5. Execute e Valide
- Rode os testes com `npm run test:integration`.
- Verifique se todos os cenÃ¡rios foram cobertos.
- Garanta que o comportamento da aplicaÃ§Ã£o estÃ¡ conforme as regras definidas.

---

### ğŸ¯ Foco dos Testes de IntegraÃ§Ã£o

O objetivo Ã© validar a aplicaÃ§Ã£o **como um sistema em funcionamento**, garantindo:
- Que todas as camadas estÃ£o corretamente conectadas.
- Que os dados fluem de forma consistente entre entradas (DTOs), lÃ³gicas de negÃ³cio e persistÃªncia.
- Que erros esperados sÃ£o tratados e retornados corretamente.

## ğŸ“¦ Estrutura dos Testes

Todos os testes de integraÃ§Ã£o seguem a seguinte estrutura:

```
tests/
 â””â”€â”€ integration/
     â”œâ”€â”€ config/
     |    â””â”€â”€ seeds/         # FunÃ§Ãµes para gerar dados de teste
     |    â””â”€â”€ setup/         # ConfiguraÃ§Ã£o do ambiente de teste
     â”œâ”€â”€ application/<nome-da-entidade>/ # Pasta para entidade (ex: measures, station)
          â””â”€â”€ <nome-do-usecase>.test.ts
```

### Detalhamento dos DiretÃ³rios:

- `config/seeds/`: ContÃ©m funÃ§Ãµes que preparam os dados necessÃ¡rios para os testes. Cada seed deve utilizar os *use cases* reais do sistema para criar os dados.
- `config/setup/`: Possui arquivos para inicializaÃ§Ã£o do banco de dados de teste, limpeza entre os testes e configuraÃ§Ã£o do ambiente.
- `application/<nome-da-entidade>/`: DiretÃ³rios organizados por domÃ­nio (ex: measures, station, parameters).
- `*.test.ts`: Arquivos com os testes de integraÃ§Ã£o, nomeados conforme o use case testado.


## ğŸ§ª Passo a Passo para Criar um Novo Teste de IntegraÃ§Ã£o

### 1. Identificar o Use Case a ser Testado

Primeiro, identifique claramente qual *use case* vocÃª precisa testar. Verifique no Jira os critÃ©rios de aceitaÃ§Ã£o e regras de negÃ³cio relacionadas.

### 2. Criar o Arquivo de Teste na Pasta Correta

O nome do arquivo de teste deve seguir o padrÃ£o:  
`<NomeDoUseCase>.test.ts`  

Exemplo: Para testar a criaÃ§Ã£o de mediÃ§Ãµes, crie o arquivo:
`tests/integration/application/measures/CreateMeasureUseCase.test.ts`

### 3. Estrutura Base do Arquivo de Teste

```ts
import { DataSource } from "typeorm";
import SetupIntegration, { getDataSource } from "../config/setup/SetupIntegration";
import { clearDatabase } from "../config/setup/DatabaseCleaner";

// Importar os repositÃ³rios e use cases necessÃ¡rios
import { NomeDoUseCase } from "../../../src/application/use-cases/pasta/NomeDoUseCase";
import { NomeDoRepositorio } from "../../../src/infrastructure/repositories/NomeDoRepositorio";

// Declarar variÃ¡veis que serÃ£o utilizadas nos testes
let dataSource: DataSource;
let useCase: NomeDoUseCase;
let repositorio: NomeDoRepositorio;

// Configurar o ambiente antes de todos os testes
beforeAll(async () => {
  await SetupIntegration();
  dataSource = getDataSource();
});

// Limpar o banco e configurar as instÃ¢ncias antes de cada teste
beforeEach(async () => {
  await clearDatabase(dataSource);
  repositorio = new NomeDoRepositorio();
  useCase = new NomeDoUseCase(repositorio);
  // Inicialize outros repositÃ³rios ou dependÃªncias necessÃ¡rias
});

// Limpar recursos apÃ³s todos os testes
afterAll(async () => {
  await dataSource.destroy();
});

// Exemplo de teste bem-sucedido
test('âœ… Deve executar com sucesso o caso de uso', async () => {
  // Preparar os dados utilizando seeds
  // Executar o caso de uso
  // Verificar os resultados com expects
});

// Exemplo de teste de erro
test('âŒ Deve retornar erro quando [condiÃ§Ã£o de erro]', async () => {
  // Preparar o cenÃ¡rio de erro
  // Verificar se o erro Ã© lanÃ§ado corretamente
  await expect(
    // Chamada do use case com parÃ¢metros que devem gerar erro
  ).rejects.toThrow("Mensagem de erro esperada");
});
```

## ğŸŒ± Como Criar e Utilizar Seeds

As seeds sÃ£o fundamentais para preparar o ambiente de teste com dados consistentes. Sempre crie os dados utilizando os *use cases* reais, nunca inserindo diretamente no banco.

### Estrutura de uma Seed:

```ts
// config/seeds/createNomeEntidadeSeed.ts
import { UseCase } from "../../../src/application/use-cases/pasta/UseCase";
import { Repositorio } from "../../../src/infrastructure/repositories/Repositorio";
import { DTO } from "../../../src/web/dtos/pasta/DTO";

export async function createNomeEntidadeSeed(parametro1: string, parametro2: number) {
  // Instanciar o use case e repositÃ³rios necessÃ¡rios
  const useCase = new UseCase(new Repositorio());
  
  // Criar o DTO com os dados de teste
  const dto = new DTO(parametro1, parametro2);
  
  // Executar o use case e retornar a entidade criada
  return await useCase.execute(dto);
}
```

### Exemplo Real de Seed para EstaÃ§Ã£o:

```ts
// createStationSeed.ts
import { CreateStationUseCase } from "../../../src/application/use-cases/station/CreateStationUseCase";
import StationRepository from "../../../src/infrastructure/repositories/StationRepository";
import CreateStationDTO from "../../../src/web/dtos/station/CreateStationDTO";

export async function createStationSeed() {
  const useCase = new CreateStationUseCase(new StationRepository());
  const dto = new CreateStationDTO("EstaÃ§Ã£o Centro", "uuid-centro", "-23.5505", "-46.6333");
  return await useCase.execute(dto);
}
```

### Utilizando Seeds nos Testes:

```ts
test('âœ… Deve criar uma mediÃ§Ã£o', async () => {
  // CriaÃ§Ã£o dos dados necessÃ¡rios usando seeds
  const station = await createStationSeed();
  const typeParameter = await createTypeParameterSeed();
  const parameter = await createParameterSeed(typeParameter, station);
  
  // Executar o caso de uso a ser testado
  const measure = await createMeasuresSeed(parameter.id);

  // ValidaÃ§Ã£o dos resultados
  expect(measure).toBeDefined();
  expect(measure.parameter.id).toBe(parameter.id);
  expect(measure.parameter.idTypeParameter).toEqual(typeParameter);
  expect(measure.parameter.idStation).toEqual(station);
});
```

## âš™ï¸ ConfiguraÃ§Ã£o do Ambiente de Testes

### Arquivos de ConfiguraÃ§Ã£o:

- **SetupIntegration.ts**: Inicializa o TypeORM com o banco de dados de teste. 
- **DatabaseCleaner.ts**: Limpa todas as tabelas do banco entre os testes.
- **TeardownIntegration.ts**: Encerra as conexÃµes apÃ³s os testes.

### Executando os Testes:

```bash
# Executa todos os testes de integraÃ§Ã£o
npm run test:integration
```

### ğŸ“š VersÃµes das Bibliotecas

Para garantir a compatibilidade e funcionamento correto dos testes, utilize as seguintes versÃµes das bibliotecas principais:

```json
{
  "dependencies": {
    "typeorm": "^0.3.20",
    "pg": "^8.11.3",
    "testcontainers": "^10.0.0",
    "jest": "^29.7.0",
    "@types/jest": "^29.5.12",
    "ts-jest": "^29.1.2"
  }
}
```

### âš™ï¸ ConfiguraÃ§Ã£o do jest

```ts
module.exports = {
    testMatch: [
        "**/tests/integration/*.test.ts",
        "**/tests/integration/**/*.test.ts",
        "**/tests/integration/**/**/*.test.ts",
      ],
    testPathIgnorePatterns: ["/node_modules/"],
    coverageDirectory: "coverage/integration",
    coverageReporters: ["text", "lcov"],
    collectCoverage: true,
    testEnvironment: "node",
    moduleNameMapper: {
      "^@/(.)$": "<rootDir>/src/$1",
    },
    preset: "ts-jest",
    globalSetup: './tests/integration/config/setup/SetupIntegration.ts',
    globalTeardown: './tests/integration/config/setup/TeardownIntegration.ts',
    testTimeout: 60000,
  };
```

## ğŸ¯ PrÃ¡ticas Recomendadas

1. **Dados consistentes**:
   - Sempre use seeds para criar dados de teste
   - Nunca faÃ§a manipulaÃ§Ã£o direta do banco
   - Mantenha os dados realistas

2. **NomeaÃ§Ã£o clara**:
   - Testes com nomes descritivos indicando o cenÃ¡rio
   - Prefixo "âœ…" para testes de sucesso
   - Prefixo "âŒ" para testes de falha

3. **ValidaÃ§Ãµes completas**:
   - Teste todas as propriedades relevantes
   - Valide casos de borda e exceÃ§Ãµes
   - Verifique mensagens de erro especÃ­ficas

4. **Isolamento**:
   - Cada teste deve ser independente
   - O banco deve ser limpo entre cada teste
   - Evite dependÃªncias entre testes

## âœ… Checklist de Qualidade

Antes de finalizar sua implementaÃ§Ã£o de testes, verifique:

- [ ] Os testes cobrem todos os cenÃ¡rios definidos nos critÃ©rios de aceitaÃ§Ã£o
- [ ] Os dados sÃ£o preparados via seeds usando use cases reais
- [ ] Existem testes para todos os casos de erro relevantes
- [ ] O banco de dados Ã© limpo corretamente entre os testes
- [ ] As mensagens de erro esperadas estÃ£o sendo validadas
- [ ] A cobertura de cÃ³digo estÃ¡ adequada (>80%)
- [ ] Os testes sÃ£o legÃ­veis e bem documentados

---

**Com testes de integraÃ§Ã£o bem estruturados, garantimos que o sistema funciona corretamente como um todo, reduzindo riscos em produÃ§Ã£o e aumentando a confianÃ§a no cÃ³digo.**